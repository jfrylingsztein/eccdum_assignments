{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXe3Ejk98wty"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ECCDUM/eccdum_assignments/blob/main/Cleaning-a-dataset.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENLNW0Ta8wt3"
      },
      "source": [
        "# Objective\n",
        "\n",
        "The objective of this notebook is get hands-on experience on cleaning a \"dirty\" dataset.\n",
        "Often, datasets are created from \"free-text\" fields. In free-text fields, data validation is not enforced and as a result, many conventions co-exist within the same column of data.\n",
        "Dirty data can also ocurr when collection information from different sources. If these sources use different conventions to represent such data, additional efforts are required to homogenize it at a later stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npSk3MAM8wt4"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "tnmzAu1E8wt5",
        "outputId": "96aca3e5-b404-4d79-c175-f3a34b35d581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q eccd_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "5KSCJTzE8wt6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from eccd_datasets import load_lingerie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "3MVsCy0H8wt7"
      },
      "outputs": [],
      "source": [
        "datasets = load_lingerie()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "u0BMN8fJ8wt7"
      },
      "outputs": [],
      "source": [
        "datasets[\"ae_com\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "aoEPVJaf8wt7"
      },
      "outputs": [],
      "source": [
        "datasets.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG9ze4db8wt8"
      },
      "source": [
        "## The different datasets on their own\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "iv71EVsB8wt8"
      },
      "outputs": [],
      "source": [
        "datasets[\"ae_com\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "WDzEL-co8wt8"
      },
      "outputs": [],
      "source": [
        "datasets[\"amazon_com\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "Kgl82yMj8wt9"
      },
      "outputs": [],
      "source": [
        "### Joining all the datasets into one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "d6qDZr9I8wt9"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(datasets.values()).reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOKNs24o8wt9"
      },
      "source": [
        "# Calculating statistics on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQEjTSyO8wt9"
      },
      "source": [
        "## Unifying Victoria's Secret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "blg1ZXdY8wt9"
      },
      "outputs": [],
      "source": [
        "def unify_victoria_secret(df):\n",
        "    \"\"\"\n",
        "    We want that all brands that are related to Victoria's Secret\n",
        "    have `victoria's secret` as their brand instead of what they\n",
        "    currently have.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    new_string = \"victoria's secret\"\n",
        "    # Write your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "Hv1eHzLY8wt-"
      },
      "outputs": [],
      "source": [
        "df_unified = unify_victoria_secret(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "dy-5B9nq8wt-"
      },
      "outputs": [],
      "source": [
        "answer_victoria_secret = df_unified[df_unified[\"brand_name\"] == \"victoria's secret\"].shape[0]\n",
        "print(answer_victoria_secret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWCWyh8_8wt-"
      },
      "source": [
        "## Cleaning up the price\n",
        "\n",
        "In this sectino we are going to transform the `price` column into a float column in USD dolars.\n",
        "\n",
        "For this, be careful of the different formats in the data.\n",
        "\n",
        "For simplicity, you might assume that all the prices are in USD dolars, regarding of the symbol of the currency used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "Cv_55t9G8wt-"
      },
      "outputs": [],
      "source": [
        "def clean_price(df):\n",
        "    \"\"\"\n",
        "    In this function we will transform the\n",
        "    `price` column into a column of floats.\n",
        "    In case a product has more than one price,\n",
        "    return the lowest one.\n",
        "    \"\"\"\n",
        "\n",
        "    # Write your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "HIX5eZYU8wt-"
      },
      "outputs": [],
      "source": [
        "df_clean = clean_price(df_unified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ICnoqbCi8wt-"
      },
      "outputs": [],
      "source": [
        "answer_unified_price_sum = df_clean[\"price\"].sum()\n",
        "print(answer_unified_price_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "R8mAmtS28wt-"
      },
      "outputs": [],
      "source": [
        "def low_high_product_mean(df):\n",
        "    \"\"\"\n",
        "    Finally, we will calculate `product_category` with the lowest and highest mean price\n",
        "    for the brand Victoria's Secret.\n",
        "    \"\"\"\n",
        "\n",
        "    # Write your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "yY4OUUP78wt_"
      },
      "outputs": [],
      "source": [
        "lowest_mean, highest_mean = low_high_product_mean(df_clean)\n",
        "assert np.allclose(lowest_mean, 3.6203030303030)\n",
        "print(\"highest_mean\", highest_mean)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}